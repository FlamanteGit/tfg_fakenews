{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta for fake news detection\n"
      ],
      "metadata": {
        "id": "yCuBZU6iydnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that you are using GPU"
      ],
      "metadata": {
        "id": "B79lXyf-ypHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWpxmVSayazf"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the type of gpu available for you:"
      ],
      "metadata": {
        "id": "Np_FymoPy25r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Pg0bhGKSyzmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load the data"
      ],
      "metadata": {
        "id": "yPL1qcW0zAb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root = 'drive/My Drive/TFG/'"
      ],
      "metadata": {
        "id": "UTBHpvISzDcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MULTIMODAL_ONLY = True # if False, we will load all the\n",
        "nameFile = 'multimodal_'\n",
        "if not MULTIMODAL_ONLY:\n",
        "    nameFile ='all_'\n",
        "\n",
        "NUM_CLASSES = 6 # 2, 3 or 6\n",
        "\n",
        "labels = []\n",
        "if NUM_CLASSES == 2:\n",
        "    labels= [\"True\", \"False\"]\n",
        "    reorder= [\"True\", \"False\"]\n",
        "\n",
        "elif NUM_CLASSES == 3:\n",
        "    labels= [\"True\", \"Fake contains True\", \"False\"]\n",
        "    reorder= [\"True\", \"Fake contains True\", \"False\"]\n",
        "\n",
        "elif NUM_CLASSES == 6:\n",
        "    labels= [\"True\", \"Satire/Parody\", \"Misleading Content\", \"Imposter Content\", \"False Connection\", \"Manipulated Content\"]\n",
        "    reorder= [\"True\", \"Satire\", \"Misleading\", \"Imposter\", \"False\", \"Manipulated\"]"
      ],
      "metadata": {
        "id": "TSUw5SS4DuQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(root+\"data/fakeddit/\" + nameFile+ \"train.tsv\", sep='\\t')\n",
        "val  = pd.read_csv(root+\"data/fakeddit/\" + nameFile+ \"validate.tsv\", sep='\\t')\n",
        "test  = pd.read_csv(root+\"data/fakeddit/\" + nameFile+ \"test_public.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Dataset: \", nameFile)\n",
        "print('size training: ', len(train))\n",
        "print('size validation: ', len(val))\n",
        "print('size test: ', len(test))\n"
      ],
      "metadata": {
        "id": "-XgH1K-mzPaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "a34BexDrKIOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "reduction = 10 #100, 10 or 1\n",
        "\n",
        "print(\"reduction applied: \", reduction)\n",
        "\n",
        "\n",
        "print(f\"Training patterns before reduction: {len(train)}\")\n",
        "train = train.sample(int(len(train)/reduction), random_state=12345)\n",
        "print(f\"Training patterns after reduction:  {len(train)}\")\n",
        "\n",
        "print(f\"Validation patterns before reduction: {len(val)}\")\n",
        "val = val.sample(int(len(val)/reduction), random_state=12345)\n",
        "print(f\"Validation patterns after reduction:  {len(val)}\")\n",
        "\n",
        "print(f\"Test patterns before reduction: {len(test)}\")\n",
        "test = test.sample(int(len(test)/reduction), random_state=12345)\n",
        "print(f\"Test patterns after reduction:  {len(test)}\")"
      ],
      "metadata": {
        "id": "6NEHRZBAZlk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize data"
      ],
      "metadata": {
        "id": "c_4tmG76e5Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(1, 3 , figsize=(10,5))\n",
        "print(labels)\n",
        "train.value_counts(str(NUM_CLASSES)+'_way_label').plot(kind='bar', ax=axes[0])\n",
        "plt.sca(axes[0])\n",
        "plt.xticks(rotation=45, horizontalalignment='right')\n",
        "plt.title('Training Dataset')\n",
        "plt.ylabel('Counts')\n",
        "\n",
        "val.value_counts(str(NUM_CLASSES)+'_way_label').plot(kind='bar', ax=axes[1])\n",
        "plt.sca(axes[1])\n",
        "plt.xticks(rotation=45, horizontalalignment='right')\n",
        "plt.title('Validation Dataset')\n",
        "\n",
        "test.value_counts(str(NUM_CLASSES)+'_way_label').plot(kind='bar', ax=axes[2])\n",
        "plt.sca(axes[2])\n",
        "plt.xticks(rotation=45, horizontalalignment='right')\n",
        "plt.title('Testing Dataset')"
      ],
      "metadata": {
        "id": "9Wrq3DG-fsfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain the maximum length (tokens) of the titles (you only see in the training and validation datasets):"
      ],
      "metadata": {
        "id": "LAYDrIHoL2uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=train[\"clean_title\"]\n",
        "x_val=val[\"clean_title\"]\n",
        "x_test=test[\"clean_title\"]\n",
        "\n",
        "\n",
        "y_train = train[str(NUM_CLASSES)+'_way_label']\n",
        "y_val = val[str(NUM_CLASSES)+'_way_label']\n",
        "y_test = test[str(NUM_CLASSES)+'_way_label']"
      ],
      "metadata": {
        "id": "C-n6uBT5Oepn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to know the maximum length (based on number of tokens) of the input sequences (from training and validation dataset) to set the parameter MAX_LENGTH. \n",
        "If the maximum length is greater than 512 (maximum lenght for BERT), we will set MAX_LENGTH to 512."
      ],
      "metadata": {
        "id": "gCtX8nAnRFfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=x_train.apply(lambda x: x.split())\n",
        "lengths=tokens.apply(lambda x: len(x))\n",
        "max_train = max(lengths)\n",
        "# print(max(lengths))\n",
        "\n",
        "tokens=x_val.apply(lambda x: x.split())\n",
        "lengths=tokens.apply(lambda x: len(x))\n",
        "max_val = max(lengths)\n",
        "# print(max(lengths))\n",
        "\n",
        "MAX_LENGTH = max(max_train, max_val)\n",
        "print(\"The maximum length of the input sequences is {} tokens\".format(MAX_LENGTH))\n",
        "\n",
        "MAX_LENGTH=min(512,MAX_LENGTH)\n",
        "print(\"MAX_LENGTH = {}\".format(MAX_LENGTH))\n"
      ],
      "metadata": {
        "id": "iyyCLiDnKPb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library transformers"
      ],
      "metadata": {
        "id": "JkvNo38kReJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "o_IIy4zkJv9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load roberta"
      ],
      "metadata": {
        "id": "tQSWG1J8RhTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import GPT2Tokenizer, TFGPT2Model, GPT2Config\n",
        "from tqdm import tqdm # Progress Bar\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "MODEL_NAME = 'gpt2'\n",
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME,  \n",
        "                                                add_special_tokens=True,\n",
        "                                                max_length=MAX_LENGTH, \n",
        "                                                pad_to_max_length=True)\n",
        "\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [], [], []\n",
        "    for sentence in tqdm(sentences):\n",
        "        inputs = tokenizer.encode_plus(sentence, \n",
        "                                       add_special_tokens=True, \n",
        "                                       max_length=MAX_LENGTH, \n",
        "                                       padding='max_length',\n",
        "                                       return_attention_mask=True, \n",
        "                                       return_token_type_ids=True, \n",
        "                                       truncation=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32')"
      ],
      "metadata": {
        "id": "ksb4IYFgKgRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize datasets (it takes a long time to load the training dataset):"
      ],
      "metadata": {
        "id": "wgGFF7fDSC8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tokenize(x_train, tokenizer)\n",
        "X_test = tokenize(x_test, tokenizer)\n",
        "X_val = tokenize(x_val, tokenizer)"
      ],
      "metadata": {
        "id": "nqXBX5mRKqma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import warnings\n",
        "from transformers import logging as hf_logging\n",
        "hf_logging.set_verbosity_error() # Hidding Huggingface Warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "-GjFPbf1SLpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model"
      ],
      "metadata": {
        "id": "jZ8lLlKsSQC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPT2Config.from_pretrained(MODEL_NAME, output_hidden_states=True, output_attentions=True)\n",
        "GPT2 = TFGPT2Model.from_pretrained(MODEL_NAME, config=config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='input_token', dtype='int32')\n",
        "input_masks_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='masked_token', dtype='int32') \n",
        "\n",
        "embedding_layer = GPT2(input_ids = input_ids_in, attention_mask = input_masks_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(X)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
        "\n",
        "for layer in model.layers[:3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Fh6JOwkDNl5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "### Create an output directory\n",
        "output_dir = './model1_outputs'\n",
        "if not os.path.exists(output_dir): ### If the file directory doesn't already exists,\n",
        "    os.makedirs(output_dir) ### Make it please"
      ],
      "metadata": {
        "id": "xXY50Z_dNvHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define callbacks"
      ],
      "metadata": {
        "id": "LtU8HqE0SR-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint(filepath=output_dir+'/weights.{epoch:02d}.hdf5',\n",
        "                                  save_weights_only=True)\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3, # Stop after 3 epochs of no improvement\n",
        "                               monitor='val_loss', # Look at validation_loss\n",
        "                               min_delta=0, # After 0 change\n",
        "                               mode='min', # Stop when quantity has stopped decreasing\n",
        "                               restore_best_weights=False, # Don't Restore the best weights\n",
        "                               verbose=1) \n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', # Look at validation loss\n",
        "                              min_lr=0.000001, # Lower bound of learning rate\n",
        "                              patience=1, # Reduce after 1 with little change\n",
        "                              mode='min', # Stop when quantity has stopped decreasing\n",
        "                              factor=0.1, # Reduce by a factor of 1/10\n",
        "                              min_delta=0.01, # Minimumn change needed\n",
        "                              verbose=1)"
      ],
      "metadata": {
        "id": "DfmwvryqOB-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, \n",
        "                    y_train, \n",
        "                    epochs = 10, #10\n",
        "                    batch_size= 16, #16\n",
        "                    validation_data=(X_val, y_val), \n",
        "                    callbacks=[model_checkpoint, early_stopping, reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4N2ur6TOEcg",
        "outputId": "b5c0e342-5a59-4e92-cb39-8d492e024617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 522/3525 [===>..........................] - ETA: 8:11 - loss: 1.3036 - accuracy: 0.5220"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    print(\"Lowest Validation Loss: epoch {}\".format(np.argmin(val_loss)+1))\n",
        "    print(\"Highest Validation Accuracy: epoch {}\".format(np.argmax(val_acc)+1))\n",
        "\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "PcBiX96sOLJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_min_val_loss_epoch(history):\n",
        "    return \"0\"+str(np.argmin(history.history['val_loss'])+1)\n",
        "\n",
        "def get_max_val_acc_epoch(history):\n",
        "    return \"0\"+str(np.argmax(history.history['val_accuracy'])+1)"
      ],
      "metadata": {
        "id": "CncmHpBGPfXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num = get_max_val_acc_epoch(history)\n",
        "model.load_weights(output_dir+\"/weights.\"+epoch_num+\".hdf5\") # Load in model weights\n"
      ],
      "metadata": {
        "id": "fayUYo9BPG10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_probs = model.predict(X_test)\n",
        "\n",
        "# Turn probabilities into an interger prediction\n",
        "y_hat = []\n",
        "for prob in y_test_probs:\n",
        "    y_hat.append(np.argmax(prob))"
      ],
      "metadata": {
        "id": "jEHhdZMZPIzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "def print_cf2(y_test, y_hat):\n",
        "    cm = confusion_matrix(y_test, y_hat)\n",
        "    sns.set(font_scale = 1.4, color_codes=True, palette=\"deep\")\n",
        "    sns.heatmap(pd.DataFrame(cm, index=labels,columns=[0,1,2,3,4,5]), \n",
        "                annot = True,\n",
        "                annot_kws = {\"size\":16},\n",
        "                fmt=\"d\",\n",
        "                cmap=\"YlGnBu\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Value\")\n",
        "    plt.xticks([0,1,2,3,4,5], labels, rotation=45)\n",
        "    plt.ylabel(\"True Value\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
        "print_cf2(y_test, y_hat)\n"
      ],
      "metadata": {
        "id": "tSDOm9yZPLPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_hat, target_names=labels))\n"
      ],
      "metadata": {
        "id": "fwGQ9vLhPNOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}