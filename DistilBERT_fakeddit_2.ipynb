{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT for fake news detection\n"
      ],
      "metadata": {
        "id": "yCuBZU6iydnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that you are using GPU"
      ],
      "metadata": {
        "id": "B79lXyf-ypHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWpxmVSayazf",
        "outputId": "15a06acb-c089-4ebc-f5ff-8b2abf48e53d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the type of gpu available for you:"
      ],
      "metadata": {
        "id": "Np_FymoPy25r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg0bhGKSyzmD",
        "outputId": "9b302710-79eb-43e8-90b2-70020804f061"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 16 15:59:58 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P8    13W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load the data"
      ],
      "metadata": {
        "id": "yPL1qcW0zAb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root = 'drive/My Drive/Colab Notebooks/'"
      ],
      "metadata": {
        "id": "UTBHpvISzDcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ec0ff8-2138-4f54-ac04-db3c1762f862"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MULTIMODAL_ONLY = True # if False, we will load all the\n",
        "nameFile = 'multimodal_'\n",
        "if not MULTIMODAL_ONLY:\n",
        "    nameFile ='all_'\n",
        "\n",
        "NUM_CLASSES = 6 # 2, 3 or 6\n",
        "\n",
        "labels = []\n",
        "if NUM_CLASSES == 2:\n",
        "    labels= [\"True\", \"False\"]\n",
        "    reorder= [\"True\", \"False\"]\n",
        "\n",
        "elif NUM_CLASSES == 3:\n",
        "    labels= [\"True\", \"Fake contains True\", \"False\"]\n",
        "    reorder= [\"True\", \"Fake contains True\", \"False\"]\n",
        "\n",
        "elif NUM_CLASSES == 6:\n",
        "    labels= [\"True\", \"Satire/Parody\", \"Misleading Content\", \"Imposter Content\", \"False Connection\", \"Manipulated Content\"]\n",
        "    reorder= [\"True\", \"Satire\", \"Misleading\", \"Imposter\", \"False\", \"Manipulated\"]"
      ],
      "metadata": {
        "id": "TSUw5SS4DuQ4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(root+\"data/fakeddit/\" + nameFile+ \"train.tsv\", sep='\\t')\n",
        "val  = pd.read_csv(root+\"data/fakeddit/\" + nameFile+ \"validate.tsv\", sep='\\t')\n",
        "test  = pd.read_csv(root+\"data/fakeddit/\" + nameFile+ \"test_public.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Dataset: \", nameFile)\n",
        "print('size training: ', len(train))\n",
        "print('size validation: ', len(val))\n",
        "print('size test: ', len(test))\n"
      ],
      "metadata": {
        "id": "-XgH1K-mzPaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fb8806-3aea-498f-8d8d-b98472186162"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:  multimodal_\n",
            "size training:  564000\n",
            "size validation:  59342\n",
            "size test:  59319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "a34BexDrKIOx",
        "outputId": "1918b76d-d1b8-47da-a980-6b48bbc22e36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                author                                        clean_title  \\\n",
              "224716          T3nd0o  this basket made out of old candy wrappers fea...   \n",
              "525216  TindalosKeeper                              ugh shitty connection   \n",
              "104777         ZAPP3Rx                                        evil racoon   \n",
              "467061  Count_Mirchaud  german tank ace michael wittmans last stand ag...   \n",
              "350361      GuysnDolls                         the dread of lancaster bay   \n",
              "\n",
              "         created_utc     domain  hasImage       id  \\\n",
              "224716  1.566649e+09  i.redd.it      True   cusqgc   \n",
              "525216  1.560360e+09        NaN      True  eqwq1xm   \n",
              "104777  1.508945e+09  i.redd.it      True   78od95   \n",
              "467061  1.481311e+09  imgur.com      True   5hfnof   \n",
              "350361  1.552235e+09        NaN      True  ei7pl4z   \n",
              "\n",
              "                                                image_url  \\\n",
              "224716  https://preview.redd.it/vz64u4m03ei31.jpg?widt...   \n",
              "525216                    https://i.imgur.com/jhHIGoj.jpg   \n",
              "104777  https://preview.redd.it/as247oqduztz.jpg?width...   \n",
              "467061  https://external-preview.redd.it/F4ThHaQXXlqf3...   \n",
              "350361                    https://i.imgur.com/RgHJ9D3.jpg   \n",
              "\n",
              "       linked_submission_id  num_comments  score          subreddit  \\\n",
              "224716                  NaN           2.0     20  mildlyinteresting   \n",
              "525216               bzptls           NaN      8   psbattle_artwork   \n",
              "104777                  NaN           0.0      4         pareidolia   \n",
              "467061                  NaN           0.0      9    fakehistoryporn   \n",
              "350361               azb1dq           NaN     11   psbattle_artwork   \n",
              "\n",
              "                                                    title  upvote_ratio  \\\n",
              "224716  This basket made out of old candy wrappers (fe...          0.80   \n",
              "525216                            Ugh, shitty connection!           NaN   \n",
              "104777                                        Evil racoon          0.70   \n",
              "467061  German Tank Ace Michael Wittman's last stand a...          0.92   \n",
              "350361                         The Dread of Lancaster Bay           NaN   \n",
              "\n",
              "        2_way_label  3_way_label  6_way_label  \n",
              "224716            1            0            0  \n",
              "525216            0            2            4  \n",
              "104777            0            2            2  \n",
              "467061            0            2            2  \n",
              "350361            0            2            4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d6ce9ed-9f75-472c-988d-290f026ff9be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>hasImage</th>\n",
              "      <th>id</th>\n",
              "      <th>image_url</th>\n",
              "      <th>linked_submission_id</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224716</th>\n",
              "      <td>T3nd0o</td>\n",
              "      <td>this basket made out of old candy wrappers fea...</td>\n",
              "      <td>1.566649e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>cusqgc</td>\n",
              "      <td>https://preview.redd.it/vz64u4m03ei31.jpg?widt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20</td>\n",
              "      <td>mildlyinteresting</td>\n",
              "      <td>This basket made out of old candy wrappers (fe...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525216</th>\n",
              "      <td>TindalosKeeper</td>\n",
              "      <td>ugh shitty connection</td>\n",
              "      <td>1.560360e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>eqwq1xm</td>\n",
              "      <td>https://i.imgur.com/jhHIGoj.jpg</td>\n",
              "      <td>bzptls</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>Ugh, shitty connection!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104777</th>\n",
              "      <td>ZAPP3Rx</td>\n",
              "      <td>evil racoon</td>\n",
              "      <td>1.508945e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>78od95</td>\n",
              "      <td>https://preview.redd.it/as247oqduztz.jpg?width...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>Evil racoon</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467061</th>\n",
              "      <td>Count_Mirchaud</td>\n",
              "      <td>german tank ace michael wittmans last stand ag...</td>\n",
              "      <td>1.481311e+09</td>\n",
              "      <td>imgur.com</td>\n",
              "      <td>True</td>\n",
              "      <td>5hfnof</td>\n",
              "      <td>https://external-preview.redd.it/F4ThHaQXXlqf3...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>German Tank Ace Michael Wittman's last stand a...</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350361</th>\n",
              "      <td>GuysnDolls</td>\n",
              "      <td>the dread of lancaster bay</td>\n",
              "      <td>1.552235e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>ei7pl4z</td>\n",
              "      <td>https://i.imgur.com/RgHJ9D3.jpg</td>\n",
              "      <td>azb1dq</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>The Dread of Lancaster Bay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d6ce9ed-9f75-472c-988d-290f026ff9be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d6ce9ed-9f75-472c-988d-290f026ff9be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d6ce9ed-9f75-472c-988d-290f026ff9be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "reduction = 10 #100, 10 or 1\n",
        "\n",
        "print(\"reduction applied: \", reduction)\n",
        "\n",
        "\n",
        "print(f\"Training patterns before reduction: {len(train)}\")\n",
        "train = train.sample(int(len(train)/reduction), random_state=12345)\n",
        "print(f\"Training patterns after reduction:  {len(train)}\")\n",
        "\n",
        "print(f\"Validation patterns before reduction: {len(val)}\")\n",
        "val = val.sample(int(len(val)/reduction), random_state=12345)\n",
        "print(f\"Validation patterns after reduction:  {len(val)}\")\n",
        "\n",
        "print(f\"Test patterns before reduction: {len(test)}\")\n",
        "test = test.sample(int(len(test)/reduction), random_state=12345)\n",
        "print(f\"Test patterns after reduction:  {len(test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NEHRZBAZlk8",
        "outputId": "b4e96915-3dd0-4425-85af-d0b59c7813b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reduction applied:  10\n",
            "Training patterns before reduction: 564000\n",
            "Training patterns after reduction:  56400\n",
            "Validation patterns before reduction: 59342\n",
            "Validation patterns after reduction:  5934\n",
            "Test patterns before reduction: 59319\n",
            "Test patterns after reduction:  5931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize data"
      ],
      "metadata": {
        "id": "c_4tmG76e5Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(1, 3 , figsize=(10,5))\n",
        "print(labels)\n",
        "train.value_counts(str(NUM_CLASSES)+'_way_label').plot(kind='bar', ax=axes[0])\n",
        "plt.sca(axes[0])\n",
        "plt.xticks(rotation=45, horizontalalignment='right')\n",
        "plt.title('Training Dataset')\n",
        "plt.ylabel('Counts')\n",
        "\n",
        "val.value_counts(str(NUM_CLASSES)+'_way_label').plot(kind='bar', ax=axes[1])\n",
        "plt.sca(axes[1])\n",
        "plt.xticks(rotation=45, horizontalalignment='right')\n",
        "plt.title('Validation Dataset')\n",
        "\n",
        "test.value_counts(str(NUM_CLASSES)+'_way_label').plot(kind='bar', ax=axes[2])\n",
        "plt.sca(axes[2])\n",
        "plt.xticks(rotation=45, horizontalalignment='right')\n",
        "plt.title('Testing Dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "9Wrq3DG-fsfX",
        "outputId": "f792282f-5d80-4093-c231-259b06dc13c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['True', 'Satire/Parody', 'Misleading Content', 'Imposter Content', 'False Connection', 'Manipulated Content']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Testing Dataset')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain the maximum length (tokens) of the titles (you only see in the training and validation datasets):"
      ],
      "metadata": {
        "id": "LAYDrIHoL2uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=train[\"clean_title\"]\n",
        "x_val=val[\"clean_title\"]\n",
        "x_test=test[\"clean_title\"]\n",
        "\n",
        "\n",
        "y_train = train[str(NUM_CLASSES)+'_way_label']\n",
        "y_val = val[str(NUM_CLASSES)+'_way_label']\n",
        "y_test = test[str(NUM_CLASSES)+'_way_label']"
      ],
      "metadata": {
        "id": "C-n6uBT5Oepn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to know the maximum length (based on number of tokens) of the input sequences (from training and validation dataset) to set the parameter MAX_LENGTH. \n",
        "If the maximum length is greater than 512 (maximum lenght for BERT), we will set MAX_LENGTH to 512."
      ],
      "metadata": {
        "id": "gCtX8nAnRFfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=x_train.apply(lambda x: x.split())\n",
        "lengths=tokens.apply(lambda x: len(x))\n",
        "max_train = max(lengths)\n",
        "# print(max(lengths))\n",
        "\n",
        "tokens=x_val.apply(lambda x: x.split())\n",
        "lengths=tokens.apply(lambda x: len(x))\n",
        "max_val = max(lengths)\n",
        "# print(max(lengths))\n",
        "\n",
        "MAX_LENGTH = max(max_train, max_val)\n",
        "print(\"The maximum length of the input sequences is {} tokens\".format(MAX_LENGTH))\n",
        "\n",
        "MAX_LENGTH=min(512,MAX_LENGTH)\n",
        "print(\"MAX_LENGTH = {}\".format(MAX_LENGTH))\n"
      ],
      "metadata": {
        "id": "iyyCLiDnKPb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bda0b3-49d2-4bff-a0fc-816f73a0772d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length of the input sequences is 127 tokens\n",
            "MAX_LENGTH = 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library transformers"
      ],
      "metadata": {
        "id": "JkvNo38kReJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_IIy4zkJv9b",
        "outputId": "0e29fe81-76eb-4dd2-f6b1-7911b2cf0d42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load distilbert"
      ],
      "metadata": {
        "id": "tQSWG1J8RhTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
        "from tqdm import tqdm # Progress Bar\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "MODEL_NAME = 'distilbert-base-cased'\n",
        "\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME,  \n",
        "                                                add_special_tokens=True,\n",
        "                                                max_length=MAX_LENGTH, \n",
        "                                                pad_to_max_length=True)\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [], [], []\n",
        "    for sentence in tqdm(sentences):\n",
        "        inputs = tokenizer.encode_plus(sentence, \n",
        "                                       add_special_tokens=True, \n",
        "                                       max_length=MAX_LENGTH, \n",
        "                                       padding='max_length',\n",
        "                                       return_attention_mask=True, \n",
        "                                       return_token_type_ids=True, \n",
        "                                       truncation=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32')"
      ],
      "metadata": {
        "id": "ksb4IYFgKgRB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize datasets (it takes a long time to load the training dataset):"
      ],
      "metadata": {
        "id": "wgGFF7fDSC8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tokenize(x_train, tokenizer)\n",
        "X_test = tokenize(x_test, tokenizer)\n",
        "X_val = tokenize(x_val, tokenizer)"
      ],
      "metadata": {
        "id": "nqXBX5mRKqma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca1eb9b-2fc5-4574-bd65-71f33e27f178"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56400/56400 [00:15<00:00, 3609.93it/s]\n",
            "100%|██████████| 5931/5931 [00:01<00:00, 3911.35it/s]\n",
            "100%|██████████| 5934/5934 [00:01<00:00, 3911.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import warnings\n",
        "from transformers import logging as hf_logging\n",
        "hf_logging.set_verbosity_error() # Hidding Huggingface Warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "-GjFPbf1SLpQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model"
      ],
      "metadata": {
        "id": "jZ8lLlKsSQC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = DistilBertConfig.from_pretrained(MODEL_NAME, output_hidden_states=True, output_attentions=True)\n",
        "DistilBERT = TFDistilBertModel.from_pretrained(MODEL_NAME, config=config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='input_token', dtype='int32')\n",
        "input_masks_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='masked_token', dtype='int32') \n",
        "\n",
        "embedding_layer = DistilBERT(input_ids = input_ids_in, attention_mask = input_masks_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(X)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
        "\n",
        "for layer in model.layers[:3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh6JOwkDNl5_",
        "outputId": "7860f439-7ab1-4479-dce4-825263140d62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 127)]        0           []                               \n",
            "                                                                                                  \n",
            " masked_token (InputLayer)      [(None, 127)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  65190912   ['input_token[0][0]',            \n",
            " BertModel)                     ast_hidden_state=(N               'masked_token[0][0]']           \n",
            "                                one, 127, 768),                                                   \n",
            "                                 hidden_states=((No                                               \n",
            "                                ne, 127, 768),                                                    \n",
            "                                 (None, 127, 768),                                                \n",
            "                                 (None, 127, 768),                                                \n",
            "                                 (None, 127, 768),                                                \n",
            "                                 (None, 127, 768),                                                \n",
            "                                 (None, 127, 768),                                                \n",
            "                                 (None, 127, 768)),                                               \n",
            "                                 attentions=((None,                                               \n",
            "                                 12, None, 127),                                                  \n",
            "                                 (None, 12, None, 1                                               \n",
            "                                27),                                                              \n",
            "                                 (None, 12, None, 1                                               \n",
            "                                27),                                                              \n",
            "                                 (None, 12, None, 1                                               \n",
            "                                27),                                                              \n",
            "                                 (None, 12, None, 1                                               \n",
            "                                27),                                                              \n",
            "                                 (None, 12, None, 1                                               \n",
            "                                27)))                                                             \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 127, 256)     918528      ['tf_distil_bert_model[0][13]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 256)         0           ['bidirectional[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           16448       ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 6)            390         ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,126,278\n",
            "Trainable params: 935,366\n",
            "Non-trainable params: 65,190,912\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "### Create an output directory\n",
        "output_dir = './model1_outputs'\n",
        "if not os.path.exists(output_dir): ### If the file directory doesn't already exists,\n",
        "    os.makedirs(output_dir) ### Make it please"
      ],
      "metadata": {
        "id": "xXY50Z_dNvHN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define callbacks"
      ],
      "metadata": {
        "id": "LtU8HqE0SR-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint(filepath=output_dir+'/weights.{epoch:02d}.hdf5',\n",
        "                                  save_weights_only=True)\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3, # Stop after 3 epochs of no improvement\n",
        "                               monitor='val_loss', # Look at validation_loss\n",
        "                               min_delta=0, # After 0 change\n",
        "                               mode='min', # Stop when quantity has stopped decreasing\n",
        "                               restore_best_weights=False, # Don't Restore the best weights\n",
        "                               verbose=1) \n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', # Look at validation loss\n",
        "                              min_lr=0.000001, # Lower bound of learning rate\n",
        "                              patience=1, # Reduce after 1 with little change\n",
        "                              mode='min', # Stop when quantity has stopped decreasing\n",
        "                              factor=0.1, # Reduce by a factor of 1/10\n",
        "                              min_delta=0.01, # Minimumn change needed\n",
        "                              verbose=1)"
      ],
      "metadata": {
        "id": "DfmwvryqOB-Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, \n",
        "                    y_train, \n",
        "                    epochs = 10, #10\n",
        "                    batch_size= 16, #16\n",
        "                    validation_data=(X_val, y_val), \n",
        "                    callbacks=[model_checkpoint, early_stopping, reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4N2ur6TOEcg",
        "outputId": "f626c18e-769d-4304-d673-cffdb21df459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3525/3525 [==============================] - 350s 97ms/step - loss: 0.9149 - accuracy: 0.6688 - val_loss: 0.7945 - val_accuracy: 0.7080 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "  70/3525 [..............................] - ETA: 5:03 - loss: 0.7918 - accuracy: 0.7286"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    print(\"Lowest Validation Loss: epoch {}\".format(np.argmin(val_loss)+1))\n",
        "    print(\"Highest Validation Accuracy: epoch {}\".format(np.argmax(val_acc)+1))\n",
        "\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "PcBiX96sOLJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_min_val_loss_epoch(history):\n",
        "    return \"0\"+str(np.argmin(history.history['val_loss'])+1)\n",
        "\n",
        "def get_max_val_acc_epoch(history):\n",
        "    return \"0\"+str(np.argmax(history.history['val_accuracy'])+1)"
      ],
      "metadata": {
        "id": "CncmHpBGPfXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num = get_max_val_acc_epoch(history)\n",
        "model.load_weights(output_dir+\"/weights.\"+epoch_num+\".hdf5\") # Load in model weights\n"
      ],
      "metadata": {
        "id": "fayUYo9BPG10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_probs = model.predict(X_test)\n",
        "\n",
        "# Turn probabilities into an interger prediction\n",
        "y_hat = []\n",
        "for prob in y_test_probs:\n",
        "    y_hat.append(np.argmax(prob))"
      ],
      "metadata": {
        "id": "jEHhdZMZPIzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "def print_cf2(y_test, y_hat):\n",
        "    cm = confusion_matrix(y_test, y_hat)\n",
        "    sns.set(font_scale = 1.4, color_codes=True, palette=\"deep\")\n",
        "    sns.heatmap(pd.DataFrame(cm, index=labels,columns=[0,1,2]), \n",
        "                annot = True,\n",
        "                annot_kws = {\"size\":16},\n",
        "                fmt=\"d\",\n",
        "                cmap=\"YlGnBu\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Value\")\n",
        "    plt.xticks([0,1,2], labels, rotation=45)\n",
        "    plt.ylabel(\"True Value\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
        "print_cf2(y_test, y_hat)\n"
      ],
      "metadata": {
        "id": "tSDOm9yZPLPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_hat, target_names=labels))\n"
      ],
      "metadata": {
        "id": "fwGQ9vLhPNOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}