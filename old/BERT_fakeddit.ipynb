{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-fakeddit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT for fake news detection\n"
      ],
      "metadata": {
        "id": "yCuBZU6iydnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that you are using GPU"
      ],
      "metadata": {
        "id": "B79lXyf-ypHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWpxmVSayazf",
        "outputId": "51b0f49f-a37c-468a-9160-d9b33bd8f766"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the type of gpu available for you:"
      ],
      "metadata": {
        "id": "Np_FymoPy25r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg0bhGKSyzmD",
        "outputId": "7ddd2cef-e9bc-4611-fe73-ea73105d0af4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 30 09:02:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load the data"
      ],
      "metadata": {
        "id": "yPL1qcW0zAb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root = 'drive/My Drive/Colab Notebooks/'\n",
        "reda_root = 'drive/My Drive/TFG/'\n",
        "paht = 'drive/My Drive/Colab Notebooks/fakkedit/'"
      ],
      "metadata": {
        "id": "UTBHpvISzDcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d14061-0824-473e-e687-8e79d597a1c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MULTIMODAL_ONLY = True # if False, we will load all the\n",
        "nameFile = 'multimodal_'\n",
        "if not MULTIMODAL_ONLY:\n",
        "    nameFile ='all_'\n"
      ],
      "metadata": {
        "id": "TSUw5SS4DuQ4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(reda_root+\"data/fakeddit/\" + nameFile+ \"train.tsv\", sep='\\t')\n",
        "val  = pd.read_csv(reda_root+\"data/fakeddit/\" + nameFile+ \"validate.tsv\", sep='\\t')\n",
        "test  = pd.read_csv(reda_root+\"data/fakeddit/\" + nameFile+ \"test_public.tsv\", sep='\\t')\n",
        "\n",
        "print(\"Dataset: \", nameFile)\n",
        "print('size training: ', len(train))\n",
        "print('size validation: ', len(val))\n",
        "print('size test: ', len(test))\n"
      ],
      "metadata": {
        "id": "-XgH1K-mzPaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271eb223-a591-4f0f-d7cb-0fa8e87a10db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:  multimodal_\n",
            "size training:  564000\n",
            "size validation:  59342\n",
            "size test:  59319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make faster experimentation, we reduce the size of the datasets (of course, the results will be worse)"
      ],
      "metadata": {
        "id": "5cOCj-A_0WxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "reduction = 10 #100, 10 or 1\n",
        "\n",
        "print(\"reduction applied: \", reduction)\n",
        "\n",
        "\n",
        "print(f\"Training patterns before reduction: {len(train)}\")\n",
        "train = train.sample(int(len(train)/reduction), random_state=12345)\n",
        "print(f\"Training patterns after reduction:  {len(train)}\")\n",
        "\n",
        "print(f\"Validation patterns before reduction: {len(val)}\")\n",
        "val = val.sample(int(len(val)/reduction), random_state=12345)\n",
        "print(f\"Validation patterns after reduction:  {len(val)}\")\n",
        "\n",
        "print(f\"Test patterns before reduction: {len(test)}\")\n",
        "test = test.sample(int(len(test)/reduction), random_state=12345)\n",
        "print(f\"Test patterns after reduction:  {len(test)}\")"
      ],
      "metadata": {
        "id": "ZPxJzWJy0MvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f388b2f-25fa-41e4-d339-5e3445e8098d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reduction applied:  10\n",
            "Training patterns before reduction: 564000\n",
            "Training patterns after reduction:  56400\n",
            "Validation patterns before reduction: 59342\n",
            "Validation patterns after reduction:  5934\n",
            "Test patterns before reduction: 59319\n",
            "Test patterns after reduction:  5931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "pl3Uw2HQ0tyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "432e026a-b77a-4a40-82d0-51a4d4468115"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                author                                        clean_title  \\\n",
              "224716          T3nd0o  this basket made out of old candy wrappers fea...   \n",
              "525216  TindalosKeeper                              ugh shitty connection   \n",
              "104777         ZAPP3Rx                                        evil racoon   \n",
              "467061  Count_Mirchaud  german tank ace michael wittmans last stand ag...   \n",
              "350361      GuysnDolls                         the dread of lancaster bay   \n",
              "\n",
              "         created_utc     domain  hasImage       id  \\\n",
              "224716  1.566649e+09  i.redd.it      True   cusqgc   \n",
              "525216  1.560360e+09        NaN      True  eqwq1xm   \n",
              "104777  1.508945e+09  i.redd.it      True   78od95   \n",
              "467061  1.481311e+09  imgur.com      True   5hfnof   \n",
              "350361  1.552235e+09        NaN      True  ei7pl4z   \n",
              "\n",
              "                                                image_url  \\\n",
              "224716  https://preview.redd.it/vz64u4m03ei31.jpg?widt...   \n",
              "525216                    https://i.imgur.com/jhHIGoj.jpg   \n",
              "104777  https://preview.redd.it/as247oqduztz.jpg?width...   \n",
              "467061  https://external-preview.redd.it/F4ThHaQXXlqf3...   \n",
              "350361                    https://i.imgur.com/RgHJ9D3.jpg   \n",
              "\n",
              "       linked_submission_id  num_comments  score          subreddit  \\\n",
              "224716                  NaN           2.0     20  mildlyinteresting   \n",
              "525216               bzptls           NaN      8   psbattle_artwork   \n",
              "104777                  NaN           0.0      4         pareidolia   \n",
              "467061                  NaN           0.0      9    fakehistoryporn   \n",
              "350361               azb1dq           NaN     11   psbattle_artwork   \n",
              "\n",
              "                                                    title  upvote_ratio  \\\n",
              "224716  This basket made out of old candy wrappers (fe...          0.80   \n",
              "525216                            Ugh, shitty connection!           NaN   \n",
              "104777                                        Evil racoon          0.70   \n",
              "467061  German Tank Ace Michael Wittman's last stand a...          0.92   \n",
              "350361                         The Dread of Lancaster Bay           NaN   \n",
              "\n",
              "        2_way_label  3_way_label  6_way_label  \n",
              "224716            1            0            0  \n",
              "525216            0            2            4  \n",
              "104777            0            2            2  \n",
              "467061            0            2            2  \n",
              "350361            0            2            4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e90434ba-b85c-421b-8e62-fb66b31c66c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>hasImage</th>\n",
              "      <th>id</th>\n",
              "      <th>image_url</th>\n",
              "      <th>linked_submission_id</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224716</th>\n",
              "      <td>T3nd0o</td>\n",
              "      <td>this basket made out of old candy wrappers fea...</td>\n",
              "      <td>1.566649e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>cusqgc</td>\n",
              "      <td>https://preview.redd.it/vz64u4m03ei31.jpg?widt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20</td>\n",
              "      <td>mildlyinteresting</td>\n",
              "      <td>This basket made out of old candy wrappers (fe...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525216</th>\n",
              "      <td>TindalosKeeper</td>\n",
              "      <td>ugh shitty connection</td>\n",
              "      <td>1.560360e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>eqwq1xm</td>\n",
              "      <td>https://i.imgur.com/jhHIGoj.jpg</td>\n",
              "      <td>bzptls</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>Ugh, shitty connection!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104777</th>\n",
              "      <td>ZAPP3Rx</td>\n",
              "      <td>evil racoon</td>\n",
              "      <td>1.508945e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>78od95</td>\n",
              "      <td>https://preview.redd.it/as247oqduztz.jpg?width...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>Evil racoon</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467061</th>\n",
              "      <td>Count_Mirchaud</td>\n",
              "      <td>german tank ace michael wittmans last stand ag...</td>\n",
              "      <td>1.481311e+09</td>\n",
              "      <td>imgur.com</td>\n",
              "      <td>True</td>\n",
              "      <td>5hfnof</td>\n",
              "      <td>https://external-preview.redd.it/F4ThHaQXXlqf3...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>German Tank Ace Michael Wittman's last stand a...</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350361</th>\n",
              "      <td>GuysnDolls</td>\n",
              "      <td>the dread of lancaster bay</td>\n",
              "      <td>1.552235e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>ei7pl4z</td>\n",
              "      <td>https://i.imgur.com/RgHJ9D3.jpg</td>\n",
              "      <td>azb1dq</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>The Dread of Lancaster Bay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e90434ba-b85c-421b-8e62-fb66b31c66c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e90434ba-b85c-421b-8e62-fb66b31c66c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e90434ba-b85c-421b-8e62-fb66b31c66c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only keep the clean title and the columns for classification:"
      ],
      "metadata": {
        "id": "jMWzHdA81k1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train[[\"clean_title\", \"2_way_label\", \"3_way_label\", \"6_way_label\"]]\n",
        "val_data=val[[\"clean_title\", \"2_way_label\", \"3_way_label\", \"6_way_label\"]]\n",
        "test_data=test[[\"clean_title\", \"2_way_label\", \"3_way_label\", \"6_way_label\"]]\n",
        "# remove records with Nan values\n",
        "train_data = train_data.dropna()\n",
        "val_data = val_data.dropna()\n",
        "test_data = test_data.dropna()\n"
      ],
      "metadata": {
        "id": "S4fJM65f04Tn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "waBd194B1Ykd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "46e4664c-8b51-4892-a44f-258cb79c1364"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              clean_title  2_way_label  \\\n",
              "224716  this basket made out of old candy wrappers fea...            1   \n",
              "525216                              ugh shitty connection            0   \n",
              "104777                                        evil racoon            0   \n",
              "467061  german tank ace michael wittmans last stand ag...            0   \n",
              "350361                         the dread of lancaster bay            0   \n",
              "\n",
              "        3_way_label  6_way_label  \n",
              "224716            0            0  \n",
              "525216            2            4  \n",
              "104777            2            2  \n",
              "467061            2            2  \n",
              "350361            2            4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-163ee675-0d47-4105-a612-ff1c0ab6cf0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_title</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224716</th>\n",
              "      <td>this basket made out of old candy wrappers fea...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525216</th>\n",
              "      <td>ugh shitty connection</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104777</th>\n",
              "      <td>evil racoon</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467061</th>\n",
              "      <td>german tank ace michael wittmans last stand ag...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350361</th>\n",
              "      <td>the dread of lancaster bay</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-163ee675-0d47-4105-a612-ff1c0ab6cf0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-163ee675-0d47-4105-a612-ff1c0ab6cf0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-163ee675-0d47-4105-a612-ff1c0ab6cf0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save the texts:"
      ],
      "metadata": {
        "id": "8pnPsRs03Qq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data[\"clean_title\"].values.tolist()\n",
        "X_val = val_data[\"clean_title\"].values.tolist()\n",
        "X_test = test_data[\"clean_title\"].values.tolist()\n",
        "print(type(X_train))"
      ],
      "metadata": {
        "id": "o2fZwhZ72BRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6612d03e-0458-4f66-9e4b-6470bd8ad31f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We show some examples:"
      ],
      "metadata": {
        "id": "5sJtFRW4E0_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(X_val[0])\n",
        "print(X_test[0])\n"
      ],
      "metadata": {
        "id": "uSZxw3tJ3_eT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2c8cba-d9d7-4373-b7f5-bf0fb57c5111"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this basket made out of old candy wrappers feat some hot garlic bread\n",
            "catana contender for mortal kombat\n",
            "cutout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decide what type of classication we will address: \n",
        "- binary (2_way_label)\n",
        "- tres classes (3_way_label)\n",
        "- 6 classes (6_way_label)"
      ],
      "metadata": {
        "id": "4fuE_ZJ_1vNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TYPE_CLASSIFICATION = 6 # 2, 3 OR 6"
      ],
      "metadata": {
        "id": "2OjD_1VI2KSG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data[str(TYPE_CLASSIFICATION) + '_way_label'].values.tolist()\n",
        "y_val = val_data[str(TYPE_CLASSIFICATION) + '_way_label'].values.tolist()\n",
        "y_test = test_data[str(TYPE_CLASSIFICATION) + '_way_label'].values.tolist()\n"
      ],
      "metadata": {
        "id": "NIj97YP53Tha"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not need to encoder the labels because they are already provided as numbers. \n",
        "\n",
        "That is, in the 6_way_label, the labels are 0, 1, 2, 3, 4, 5. \n",
        "- 0: true\n",
        "- 1: Satire/Parody:\n",
        "- 2: Misleading Content\n",
        "- 3: Imposter Content\n",
        "- 4: False Connection\n",
        "- 5: Manipulated Content\n",
        "\n",
        "In the 3_way_label, the labels are 0, 1, 2:\n",
        "- 0: true\n",
        "- 1: the sample is fake and contains text that is true (i.e. direct quotes from propaganda posters)\n",
        "- 2: False\n",
        "\n",
        "In the 2_way_label, the labels are 0, 1:\n",
        "- 0: true\n",
        "- 1: False\n"
      ],
      "metadata": {
        "id": "i45R7nwO4NaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict = {}\n",
        "if TYPE_CLASSIFICATION == 2:\n",
        "    labels_dict[0] = \"True\"\n",
        "    labels_dict[1] = \"False\"\n",
        "elif TYPE_CLASSIFICATION == 3:\n",
        "    labels_dict[0] = \"True\"\n",
        "    labels_dict[1] = \"Fake contains True\"\n",
        "    labels_dict[2] = \"False\"\n",
        "elif TYPE_CLASSIFICATION == 6:\n",
        "    labels_dict[0] = \"True\"\n",
        "    labels_dict[1] = \"Satire/Parody\"\n",
        "    labels_dict[2] = \"Misleading Content\"\n",
        "    labels_dict[3] = \"Imposter Content\"\n",
        "    labels_dict[4] = \"False Connection\"\n",
        "    labels_dict[5] = \"Manipulated Content\"\n",
        "\n",
        "print(labels_dict)"
      ],
      "metadata": {
        "id": "BPDLTrIn6LaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc610f85-caac-4b44-f2a8-0930f9da0068"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'True', 1: 'Satire/Parody', 2: 'Misleading Content', 3: 'Imposter Content', 4: 'False Connection', 5: 'Manipulated Content'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We show some examples and their labels:"
      ],
      "metadata": {
        "id": "_n9La3B2E832"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0], y_train[0], labels_dict[y_train[0]])\n",
        "print(X_val[0], y_val[0], labels_dict[y_val[0]])\n",
        "print(X_test[0], y_test[0], labels_dict[y_test[0]])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PEWyU4ho2oIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42db89e4-451f-4db8-e53c-bee5aa49189f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this basket made out of old candy wrappers feat some hot garlic bread 0 True\n",
            "catana contender for mortal kombat 4 False Connection\n",
            "cutout 4 False Connection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization\n",
        "\n",
        "Here we should provide more detail about the dataset (class distribution, average lenght of the texts, etc)"
      ],
      "metadata": {
        "id": "sH9cEVWL7eef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will do it after"
      ],
      "metadata": {
        "id": "mQkDDujH7oES"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "LHmAr8AC7mIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we install the libraries:"
      ],
      "metadata": {
        "id": "yTr53tRT71SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers numpy torch sklearn\n"
      ],
      "metadata": {
        "id": "RbId8-_273Cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473fae90-a8be-4767-9327-68e20b54d233"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make our experiments reproducible, we set a random seed:\n"
      ],
      "metadata": {
        "id": "T-SI-hLj8NXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "FvnP5Zn88Nh2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary modules:"
      ],
      "metadata": {
        "id": "T2UqgU7O8cCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n"
      ],
      "metadata": {
        "id": "KE4SHkAu8d9J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll be using the BERT model. More specifically, we'll be using bert-base-uncased pre-trained weights from the library."
      ],
      "metadata": {
        "id": "x4KPOOS_8nfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the model we gonna train, base uncased BERT\n",
        "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
        "model_name = \"bert-base-uncased\"\n",
        "# max sequence length for each document/sentence sample\n",
        "max_length = 512"
      ],
      "metadata": {
        "id": "loQ3yQJC8iNO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the tokenizer provided by this model:"
      ],
      "metadata": {
        "id": "M3anFpYK8uIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
      ],
      "metadata": {
        "id": "7jJH8gBb8tW3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use our tokenizer to encode our corpus. This tokenizer translate the tokens to ids. We set truncation to True so that we eliminate tokens that go above max_length, we also set padding to True to pad documents that are less than max_length with empty tokens."
      ],
      "metadata": {
        "id": "zYJsweoW83Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the dataset, truncate when passed `max_length`, \n",
        "# and pad with 0's when less than `max_length`\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length)\n"
      ],
      "metadata": {
        "id": "JgwTmbtC86B5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code wraps our tokenized text data into a torch Dataset. Since we gonna use Trainer from Transformers library, it expects our dataset as a torch.utils.data.Dataset, so we made a simple class that implements the len() method that returns the number of samples, and getitem() method to return a data sample at a specific index."
      ],
      "metadata": {
        "id": "0Z6IcjCe9Bk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_torch_dataset = TorchDataset(train_encodings, y_train)\n",
        "val_torch_dataset = TorchDataset(val_encodings, y_val)\n",
        "test_torch_dataset = TorchDataset(test_encodings, y_test)"
      ],
      "metadata": {
        "id": "oovO3dPk9A_0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_encodings.encodings), len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbQNzihAS0sp",
        "outputId": "51b436b4-7c6f-46e6-8180-ec4dd8a67ebb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56400 56400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "\n",
        "Now that we have our data prepared, let's download and load our BERT model and its pre-trained weights. We're using BertForSequenceClassification class from Transformers library, we set num_labels to the length of our available labels, in this case, 2.\n",
        "\n",
        "We also cast our model to our CUDA GPU. If you're on CPU (not suggested), then just delete to() method."
      ],
      "metadata": {
        "id": "Caabgunu9OlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and pass to CUDA\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels = TYPE_CLASSIFICATION).to(\"cuda\")"
      ],
      "metadata": {
        "id": "K5yeXOJX9QkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00fb800-ce54-40ac-d7b6-0f7f73960e79"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start fine-tuning our model, let's make a simple function to compute the metrics we want. In this case, accuracy.\n",
        "You're free to include any metric you want, I've included accuracy, but you can add precision, recall, etc."
      ],
      "metadata": {
        "id": "42Fh_FKS9sx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "metadata": {
        "id": "59F6bL0O9r3Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,   # 3           # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "    logging_steps=100,               # log & save weights each logging_steps\n",
        "    save_steps=800,\n",
        "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
        "    report_to=\"wandb\",\n",
        ")"
      ],
      "metadata": {
        "id": "956PNiLj90wn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSj-3BPrqZyG",
        "outputId": "d2693ffa-dccd-4f53-bce6-812ee936c6b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.11)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,                         # the instantiated Transformers model to be trained\n",
        "    args = training_args,                  # training arguments, defined above\n",
        "    train_dataset = train_torch_dataset,         # training dataset\n",
        "    eval_dataset = val_torch_dataset,          # evaluation dataset\n",
        "    compute_metrics = compute_metrics,     # the callback that computes metrics of interest\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "H8_bPbIQ9311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "602a19e9-f5c7-4d6b-f239-7cd9d7f50ae7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 56400\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7050\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mflamante\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220330_090524-3p4df61x</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/flamante/huggingface/runs/3p4df61x\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/flamante/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='264' max='7050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 264/7050 04:13 < 1:49:27, 1.03 it/s, Epoch 0.04/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.678400</td>\n",
              "      <td>1.380615</td>\n",
              "      <td>0.463431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.249100</td>\n",
              "      <td>1.098990</td>\n",
              "      <td>0.615268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5934\n",
            "  Batch size = 20\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5934\n",
            "  Batch size = 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='277' max='7050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 277/7050 04:21 < 1:47:27, 1.05 it/s, Epoch 0.04/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.678400</td>\n",
              "      <td>1.380615</td>\n",
              "      <td>0.463431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.249100</td>\n",
              "      <td>1.098990</td>\n",
              "      <td>0.615268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cd3101f8b85e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1463\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_was_run\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the current model after training\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "sDGWIwbjAwmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "c7569924-c336-41a0-8cc3-59a2c9f60324"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5934\n",
            "  Batch size = 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='277' max='7050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 277/7050 04:21 < 1:47:27, 1.05 it/s, Epoch 0.04/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.678400</td>\n",
              "      <td>1.380615</td>\n",
              "      <td>0.463431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.249100</td>\n",
              "      <td>1.098990</td>\n",
              "      <td>0.615268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>1.249100</td>\n",
              "      <td>1.037354</td>\n",
              "      <td>0.635996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.6359959555106168, 'eval_loss': 1.0373536348342896}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "TVp6JDauFwcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the fine tuned model & tokenizer\n",
        "model_path = \"fake-bert-base-uncased\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "VDGlU_IqAy0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310188db-c2cb-43b2-a0b0-a04b10561c06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in fake-bert-base-uncased/config.json\n",
            "Model weights saved in fake-bert-base-uncased/pytorch_model.bin\n",
            "tokenizer config file saved in fake-bert-base-uncased/tokenizer_config.json\n",
            "Special tokens file saved in fake-bert-base-uncased/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fake-bert-base-uncased/tokenizer_config.json',\n",
              " 'fake-bert-base-uncased/special_tokens_map.json',\n",
              " 'fake-bert-base-uncased/vocab.txt',\n",
              " 'fake-bert-base-uncased/added_tokens.json',\n",
              " 'fake-bert-base-uncased/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    # return probs.argmax() is a tensor. We have to return its item\n",
        "    return probs.argmax().item()\n"
      ],
      "metadata": {
        "id": "6EGH4BlXA2eA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for text in X_test:\n",
        "    y_pred.append(get_prediction(text))\n"
      ],
      "metadata": {
        "id": "h6n8mUe1A4Wx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(labels_dict)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "ZD2SSykUA6b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85252043-4206-4752-bb28-6533863d8be0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'True', 1: 'Satire/Parody', 2: 'Misleading Content', 3: 'Imposter Content', 4: 'False Connection', 5: 'Manipulated Content'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.90      0.74      2351\n",
            "           1       0.00      0.00      0.00       376\n",
            "           2       0.43      0.12      0.18      1154\n",
            "           3       0.00      0.00      0.00       139\n",
            "           4       0.66      0.87      0.75      1675\n",
            "           5       0.00      0.00      0.00       236\n",
            "\n",
            "    accuracy                           0.62      5931\n",
            "   macro avg       0.29      0.31      0.28      5931\n",
            "weighted avg       0.52      0.62      0.54      5931\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=labels_dict)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FoviECZfsMl_",
        "outputId": "f44cffbc-69d1-4cd6-e5d2-2357bdbd85e7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We show some predictions for new texts. The second prediction is wrong (the news is fake). "
      ],
      "metadata": {
        "id": "Enk5FewuHnjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Donald Trump sent his own plane to transport 200 stranded marines.\"\n",
        "\n",
        "pred=get_prediction(text)\n",
        "print('class:', labels_dict[pred])\n",
        "\n",
        "text = \"FBI director received millions from Clinton Foundation, his brother’s law firm does Clinton’s taxes\"\n",
        "\n",
        "pred=get_prediction(text)\n",
        "print('class:', labels_dict[pred])"
      ],
      "metadata": {
        "id": "RTgbZVxRBB6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}