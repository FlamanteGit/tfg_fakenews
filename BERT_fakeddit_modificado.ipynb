{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-fakeddit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlamanteGit/tfg_multimodal/blob/master/BERT_fakeddit_modificado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT for fake news detection\n"
      ],
      "metadata": {
        "id": "yCuBZU6iydnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that you are using GPU"
      ],
      "metadata": {
        "id": "B79lXyf-ypHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWpxmVSayazf",
        "outputId": "9b0880f0-2a9f-4d64-90bc-145ca2d02466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the type of gpu available for you:"
      ],
      "metadata": {
        "id": "Np_FymoPy25r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg0bhGKSyzmD",
        "outputId": "f75c22d6-d362-4f9e-fcf5-8c57415d0602"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 23 20:04:18 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load the data"
      ],
      "metadata": {
        "id": "yPL1qcW0zAb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTBHpvISzDcy",
        "outputId": "411dccd9-6614-454a-a23f-dbfe063ce5d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"./drive/MyDrive/TFG/multimodal_train.tsv\", sep='\\t')\n",
        "val  = pd.read_csv(\"./drive/MyDrive/TFG/multimodal_validate.tsv\", sep='\\t')\n",
        "test  = pd.read_csv(\"./drive/MyDrive/TFG/multimodal_test_public.tsv\", sep='\\t')\n",
        "\n",
        "print('size training: ', len(train))\n",
        "print('size validation: ', len(val))\n",
        "print('size test: ', len(test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XgH1K-mzPaz",
        "outputId": "932fb8e9-9cbe-4748-d430-688d7bf6e52d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size training:  564000\n",
            "size validation:  59342\n",
            "size test:  59319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make faster experimentation, we reduce the size of the datasets (of course, the results will be worse)"
      ],
      "metadata": {
        "id": "5cOCj-A_0WxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(f\"Training patterns before reduction: {len(train)}\")\n",
        "#train = train.sample(int(len(train)/100), random_state=12345)\n",
        "print(f\"Training patterns after reduction:  {len(train)}\")\n",
        "\n",
        "print(f\"Training patterns before reduction: {len(val)}\")\n",
        "#val = train.sample(int(len(val)/100), random_state=12345)\n",
        "print(f\"Training patterns after reduction:  {len(val)}\")\n",
        "\n",
        "\n",
        "print(f\"Test patterns before reduction: {len(test)}\")\n",
        "#test = test.sample(int(len(test)/100), random_state=12345)\n",
        "print(f\"Test patterns after reduction:  {len(test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPxJzWJy0MvF",
        "outputId": "f3ce91c6-118b-41dc-c148-ccb81bc41be5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training patterns before reduction: 564000\n",
            "Training patterns after reduction:  5640\n",
            "Training patterns before reduction: 59342\n",
            "Training patterns after reduction:  593\n",
            "Test patterns before reduction: 59319\n",
            "Test patterns after reduction:  593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "pl3Uw2HQ0tyz",
        "outputId": "85edcb23-63b4-4ad5-fe21-f9e7a9f85680"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                author                                        clean_title  \\\n",
              "224716          T3nd0o  this basket made out of old candy wrappers fea...   \n",
              "525216  TindalosKeeper                              ugh shitty connection   \n",
              "104777         ZAPP3Rx                                        evil racoon   \n",
              "467061  Count_Mirchaud  german tank ace michael wittmans last stand ag...   \n",
              "350361      GuysnDolls                         the dread of lancaster bay   \n",
              "\n",
              "         created_utc     domain  hasImage       id  \\\n",
              "224716  1.566649e+09  i.redd.it      True   cusqgc   \n",
              "525216  1.560360e+09        NaN      True  eqwq1xm   \n",
              "104777  1.508945e+09  i.redd.it      True   78od95   \n",
              "467061  1.481311e+09  imgur.com      True   5hfnof   \n",
              "350361  1.552235e+09        NaN      True  ei7pl4z   \n",
              "\n",
              "                                                image_url  \\\n",
              "224716  https://preview.redd.it/vz64u4m03ei31.jpg?widt...   \n",
              "525216                    https://i.imgur.com/jhHIGoj.jpg   \n",
              "104777  https://preview.redd.it/as247oqduztz.jpg?width...   \n",
              "467061  https://external-preview.redd.it/F4ThHaQXXlqf3...   \n",
              "350361                    https://i.imgur.com/RgHJ9D3.jpg   \n",
              "\n",
              "       linked_submission_id  num_comments  score          subreddit  \\\n",
              "224716                  NaN           2.0     20  mildlyinteresting   \n",
              "525216               bzptls           NaN      8   psbattle_artwork   \n",
              "104777                  NaN           0.0      4         pareidolia   \n",
              "467061                  NaN           0.0      9    fakehistoryporn   \n",
              "350361               azb1dq           NaN     11   psbattle_artwork   \n",
              "\n",
              "                                                    title  upvote_ratio  \\\n",
              "224716  This basket made out of old candy wrappers (fe...          0.80   \n",
              "525216                            Ugh, shitty connection!           NaN   \n",
              "104777                                        Evil racoon          0.70   \n",
              "467061  German Tank Ace Michael Wittman's last stand a...          0.92   \n",
              "350361                         The Dread of Lancaster Bay           NaN   \n",
              "\n",
              "        2_way_label  3_way_label  6_way_label  \n",
              "224716            1            0            0  \n",
              "525216            0            2            4  \n",
              "104777            0            2            2  \n",
              "467061            0            2            2  \n",
              "350361            0            2            4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ffa2d34-afc3-4436-9cb7-3503c314f659\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>hasImage</th>\n",
              "      <th>id</th>\n",
              "      <th>image_url</th>\n",
              "      <th>linked_submission_id</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224716</th>\n",
              "      <td>T3nd0o</td>\n",
              "      <td>this basket made out of old candy wrappers fea...</td>\n",
              "      <td>1.566649e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>cusqgc</td>\n",
              "      <td>https://preview.redd.it/vz64u4m03ei31.jpg?widt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20</td>\n",
              "      <td>mildlyinteresting</td>\n",
              "      <td>This basket made out of old candy wrappers (fe...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525216</th>\n",
              "      <td>TindalosKeeper</td>\n",
              "      <td>ugh shitty connection</td>\n",
              "      <td>1.560360e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>eqwq1xm</td>\n",
              "      <td>https://i.imgur.com/jhHIGoj.jpg</td>\n",
              "      <td>bzptls</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>Ugh, shitty connection!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104777</th>\n",
              "      <td>ZAPP3Rx</td>\n",
              "      <td>evil racoon</td>\n",
              "      <td>1.508945e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>78od95</td>\n",
              "      <td>https://preview.redd.it/as247oqduztz.jpg?width...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>Evil racoon</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467061</th>\n",
              "      <td>Count_Mirchaud</td>\n",
              "      <td>german tank ace michael wittmans last stand ag...</td>\n",
              "      <td>1.481311e+09</td>\n",
              "      <td>imgur.com</td>\n",
              "      <td>True</td>\n",
              "      <td>5hfnof</td>\n",
              "      <td>https://external-preview.redd.it/F4ThHaQXXlqf3...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>German Tank Ace Michael Wittman's last stand a...</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350361</th>\n",
              "      <td>GuysnDolls</td>\n",
              "      <td>the dread of lancaster bay</td>\n",
              "      <td>1.552235e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>ei7pl4z</td>\n",
              "      <td>https://i.imgur.com/RgHJ9D3.jpg</td>\n",
              "      <td>azb1dq</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>The Dread of Lancaster Bay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ffa2d34-afc3-4436-9cb7-3503c314f659')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ffa2d34-afc3-4436-9cb7-3503c314f659 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ffa2d34-afc3-4436-9cb7-3503c314f659');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only keep the clean title and the columns for classification:"
      ],
      "metadata": {
        "id": "jMWzHdA81k1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train[[\"clean_title\", \"2_way_label\", \"3_way_label\", \"6_way_label\"]]\n",
        "val_data=val[[\"clean_title\", \"2_way_label\", \"3_way_label\", \"6_way_label\"]]\n",
        "test_data=test[[\"clean_title\", \"2_way_label\", \"3_way_label\", \"6_way_label\"]]\n",
        "\n",
        "train_data = train_data.dropna()\n",
        "val_data = val_data.dropna()\n",
        "test_data = test_data.dropna()\n"
      ],
      "metadata": {
        "id": "S4fJM65f04Tn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "waBd194B1Ykd",
        "outputId": "da5236c8-a1c6-4ae7-d1ac-cda5d329d2a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         clean_title  2_way_label  \\\n",
              "0  my walgreens offbrand mucinex was engraved wit...            1   \n",
              "1                this concerned sink with a tiny hat            0   \n",
              "2      hackers leak emails from uae ambassador to us            1   \n",
              "3                           puppy taking in the view            1   \n",
              "4               i found a face in my sheet music too            0   \n",
              "\n",
              "   3_way_label  6_way_label  \n",
              "0            0            0  \n",
              "1            2            2  \n",
              "2            0            0  \n",
              "3            0            0  \n",
              "4            2            2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8a2d97a-7027-4c52-b97c-135249679b8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_title</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this concerned sink with a tiny hat</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hackers leak emails from uae ambassador to us</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>puppy taking in the view</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i found a face in my sheet music too</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8a2d97a-7027-4c52-b97c-135249679b8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8a2d97a-7027-4c52-b97c-135249679b8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8a2d97a-7027-4c52-b97c-135249679b8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save the texts:"
      ],
      "metadata": {
        "id": "8pnPsRs03Qq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data[\"clean_title\"].values.tolist()\n",
        "X_val = val_data[\"clean_title\"].values.tolist()\n",
        "X_test = test_data[\"clean_title\"].values.tolist()\n",
        "print(type(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2fZwhZ72BRO",
        "outputId": "e3e00705-eaf9-4702-de1c-8ccb5788a181"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(X_val[0])\n",
        "print(X_test[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSZxw3tJ3_eT",
        "outputId": "534dde24-a968-4d91-c49e-6786439f5668"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this basket made out of old candy wrappers feat some hot garlic bread\n",
            "bound\n",
            "cutout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decide what type of classication we will address: \n",
        "- binary (2_way_label)\n",
        "- tres classes (3_way_label)\n",
        "- 6 classes (6_way_label)"
      ],
      "metadata": {
        "id": "4fuE_ZJ_1vNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TYPE_CLASSIFICATION = 6 # 3 OR 6"
      ],
      "metadata": {
        "id": "2OjD_1VI2KSG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data[str(TYPE_CLASSIFICATION) + '_way_label'].values.tolist()\n",
        "y_val = val_data[str(TYPE_CLASSIFICATION) + '_way_label'].values.tolist()\n",
        "y_test = test_data[str(TYPE_CLASSIFICATION) + '_way_label'].values.tolist()\n"
      ],
      "metadata": {
        "id": "NIj97YP53Tha"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not need to encoder the labels because they are already provided as numbers. \n",
        "\n",
        "That is, in the 6_way_label, the labels are 0, 1, 2, 3, 4, 5. \n",
        "- 0: true\n",
        "- 1: Satire/Parody:\n",
        "- 2: Misleading Content\n",
        "- 3: Imposter Content\n",
        "- 4: False Connection\n",
        "- 5: Manipulated Content\n",
        "\n",
        "In the 3_way_label, the labels are 0, 1, 2:\n",
        "- 0: true\n",
        "- 1: the sample is fake and contains text that is true (i.e. direct quotes from propaganda posters)\n",
        "- 2: False\n",
        "\n",
        "In the 2_way_label, the labels are 0, 1:\n",
        "- 0: true\n",
        "- 1: False\n"
      ],
      "metadata": {
        "id": "i45R7nwO4NaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict = {}\n",
        "if TYPE_CLASSIFICATION == 2:\n",
        "    labels_dict[0] = \"True\"\n",
        "    labels_dict[1] = \"False\"\n",
        "elif TYPE_CLASSIFICATION == 3:\n",
        "    labels_dict[0] = \"True\"\n",
        "    labels_dict[1] = \"Fake contains True\"\n",
        "    labels_dict[2] = \"False\"\n",
        "elif TYPE_CLASSIFICATION == 6:\n",
        "    labels_dict[0] = \"True\"\n",
        "    labels_dict[1] = \"Satire/Parody\"\n",
        "    labels_dict[2] = \"Misleading Content\"\n",
        "    labels_dict[3] = \"Imposter Content\"\n",
        "    labels_dict[4] = \"False Connection\"\n",
        "    labels_dict[5] = \"Manipulated Content\"\n",
        "\n",
        "print(labels_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPDLTrIn6LaE",
        "outputId": "bb284035-9738-4a0c-ee5f-55d5d99454dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'True', 1: 'False'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0], y_train[0], labels_dict[y_train[0]])\n",
        "print(X_val[0], y_val[0], labels_dict[y_val[0]])\n",
        "print(X_test[0], y_test[0], labels_dict[y_test[0]])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "PEWyU4ho2oIw",
        "outputId": "72c0ff36-34c4-4ea3-8fe8-8904caa0f808"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c70c471fa111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization\n",
        "\n",
        "Here we should provide more detail about the dataset (class distribution, average lenght of the texts, etc)"
      ],
      "metadata": {
        "id": "sH9cEVWL7eef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "\n",
        "num_classes = len(train_data[str(TYPE_CLASSIFICATION) + '_way_label'].value_counts())\n",
        "\n",
        "colors = plt.cm.Dark2(np.linspace(0, 1, num_classes))\n",
        "iter_color = iter(colors)\n",
        "\n",
        "train_data[str(TYPE_CLASSIFICATION) + '_way_label'].value_counts().plot.barh(title=\"Distribution\", \n",
        "                                                 ylabel=str(TYPE_CLASSIFICATION) + '_way_label',\n",
        "                                                 color=colors,\n",
        "                                                 figsize=(9,9))\n",
        "\n",
        "for i, v in enumerate(train_data[str(TYPE_CLASSIFICATION) + '_way_label'].value_counts()):\n",
        "  c = next(iter_color)\n",
        "  plt.text(v, i,\n",
        "           \" \"+str(v)+\", \"+str(round(v*100/train_data.shape[0],2))+\"%\", \n",
        "           color=c, \n",
        "           va='center', \n",
        "           fontweight='bold')"
      ],
      "metadata": {
        "id": "mQkDDujH7oES",
        "outputId": "7b9eb645-c6e4-4705-ddc3-33078b281ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "LHmAr8AC7mIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we install the libraries:"
      ],
      "metadata": {
        "id": "yTr53tRT71SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers numpy torch sklearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbId8-_273Cy",
        "outputId": "006f8c3d-b167-4e2e-b827-f862dd6c92bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make our experiments reproducible, we set a random seed:\n"
      ],
      "metadata": {
        "id": "T-SI-hLj8NXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "FvnP5Zn88Nh2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary modules:"
      ],
      "metadata": {
        "id": "T2UqgU7O8cCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "KE4SHkAu8d9J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll be using the BERT model. More specifically, we'll be using bert-base-uncased pre-trained weights from the library."
      ],
      "metadata": {
        "id": "x4KPOOS_8nfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the model we gonna train, base uncased BERT\n",
        "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
        "model_name = \"bert-base-uncased\"\n",
        "# max sequence length for each document/sentence sample\n",
        "max_length = 512"
      ],
      "metadata": {
        "id": "loQ3yQJC8iNO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the tokenizer provided by this model:"
      ],
      "metadata": {
        "id": "M3anFpYK8uIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
      ],
      "metadata": {
        "id": "7jJH8gBb8tW3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use our tokenizer to encode our corpus. We set truncation to True so that we eliminate tokens that go above max_length, we also set padding to True to pad documents that are less than max_length with empty tokens."
      ],
      "metadata": {
        "id": "zYJsweoW83Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the dataset, truncate when passed `max_length`, \n",
        "# and pad with 0's when less than `max_length`\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length)\n",
        "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length)\n"
      ],
      "metadata": {
        "id": "JgwTmbtC86B5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code wraps our tokenized text data into a torch Dataset. Since we gonna use Trainer from Transformers library, it expects our dataset as a torch.utils.data.Dataset, so we made a simple class that implements the len() method that returns the number of samples, and getitem() method to return a data sample at a specific index."
      ],
      "metadata": {
        "id": "0Z6IcjCe9Bk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_torch_dataset = TorchDataset(train_encodings, y_train)\n",
        "val_torch_dataset = TorchDataset(val_encodings, y_test)\n",
        "test_torch_dataset = TorchDataset(test_encodings, y_test)"
      ],
      "metadata": {
        "id": "oovO3dPk9A_0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "\n",
        "Now that we have our data prepared, let's download and load our BERT model and its pre-trained weights. We're using BertForSequenceClassification class from Transformers library, we set num_labels to the length of our available labels, in this case, 2.\n",
        "\n",
        "We also cast our model to our CUDA GPU. If you're on CPU (not suggested), then just delete to() method."
      ],
      "metadata": {
        "id": "Caabgunu9OlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and pass to CUDA\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels = TYPE_CLASSIFICATION).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5yeXOJX9QkB",
        "outputId": "6c38adb1-e688-411f-8f7a-a90148ae2b99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start fine-tuning our model, let's make a simple function to compute the metrics we want. In this case, accuracy.\n",
        "You're free to include any metric you want, I've included accuracy, but you can add precision, recall, etc."
      ],
      "metadata": {
        "id": "42Fh_FKS9sx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "metadata": {
        "id": "59F6bL0O9r3Y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "    logging_steps=400,               # log & save weights each logging_steps\n",
        "    save_steps=400,\n",
        "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
        ")"
      ],
      "metadata": {
        "id": "956PNiLj90wn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset= train_torch_dataset,         # training dataset\n",
        "    eval_dataset= val_torch_dataset,          # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H8_bPbIQ9311",
        "outputId": "78b714a1-0862-45b8-891e-01c0a0c0a4d8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 5640\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2115\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2115' max='2115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2115/2115 10:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.705100</td>\n",
              "      <td>1.183722</td>\n",
              "      <td>0.475548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.489100</td>\n",
              "      <td>2.007843</td>\n",
              "      <td>0.418212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.385800</td>\n",
              "      <td>2.377595</td>\n",
              "      <td>0.430017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.259800</td>\n",
              "      <td>3.372530</td>\n",
              "      <td>0.431703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.159700</td>\n",
              "      <td>3.690994</td>\n",
              "      <td>0.436762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 593\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-400\n",
            "Configuration saved in ./results/checkpoint-400/config.json\n",
            "Model weights saved in ./results/checkpoint-400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 593\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-800\n",
            "Configuration saved in ./results/checkpoint-800/config.json\n",
            "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 593\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-1200\n",
            "Configuration saved in ./results/checkpoint-1200/config.json\n",
            "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 593\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-1600\n",
            "Configuration saved in ./results/checkpoint-1600/config.json\n",
            "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 593\n",
            "  Batch size = 20\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-400 (score: 1.1837222576141357).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2115, training_loss=0.385834109078626, metrics={'train_runtime': 615.7634, 'train_samples_per_second': 27.478, 'train_steps_per_second': 3.435, 'total_flos': 565179954721200.0, 'train_loss': 0.385834109078626, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the current model after training\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "sDGWIwbjAwmq",
        "outputId": "4c32febb-4544-4b15-fbff-f96cb0df046e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 593\n",
            "  Batch size = 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.47554806070826305,\n",
              " 'eval_loss': 1.1837222576141357,\n",
              " 'eval_runtime': 3.7022,\n",
              " 'eval_samples_per_second': 160.177,\n",
              " 'eval_steps_per_second': 8.103}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the fine tuned model & tokenizer\n",
        "model_path = \"fake-bert-base-uncased\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "VDGlU_IqAy0Q",
        "outputId": "febc010f-e4d9-465d-cd81-2b4085e0d1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in fake-bert-base-uncased/config.json\n",
            "Model weights saved in fake-bert-base-uncased/pytorch_model.bin\n",
            "tokenizer config file saved in fake-bert-base-uncased/tokenizer_config.json\n",
            "Special tokens file saved in fake-bert-base-uncased/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fake-bert-base-uncased/tokenizer_config.json',\n",
              " 'fake-bert-base-uncased/special_tokens_map.json',\n",
              " 'fake-bert-base-uncased/vocab.txt',\n",
              " 'fake-bert-base-uncased/added_tokens.json',\n",
              " 'fake-bert-base-uncased/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(text):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    # return probs.argmax() is a tensor. We have to return its item\n",
        "    return probs.argmax().item()\n"
      ],
      "metadata": {
        "id": "6EGH4BlXA2eA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for text in X_test:\n",
        "    y_pred.append(get_prediction(text))\n"
      ],
      "metadata": {
        "id": "h6n8mUe1A4Wx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "ZD2SSykUA6b1",
        "outputId": "a5758cf5-b54f-411d-dc8c-eb429d9fed56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.47      0.60       249\n",
            "           1       0.50      0.06      0.11        16\n",
            "           2       0.68      0.94      0.79       328\n",
            "\n",
            "    accuracy                           0.72       593\n",
            "   macro avg       0.67      0.49      0.50       593\n",
            "weighted avg       0.74      0.72      0.69       593\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(labels_dict.keys())\n"
      ],
      "metadata": {
        "id": "yA7m_prmW-tS",
        "outputId": "2bcca54b-98df-47c3-b902-f30c6aef8d7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred, labels=list(labels_dict.keys())))"
      ],
      "metadata": {
        "id": "GmE57-n3Kphv",
        "outputId": "99034507-ebcb-41b1-acc8-2c06d9d6257e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[116   1 132]\n",
            " [  0   1  15]\n",
            " [ 21   0 307]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"There’s a cheesy charm to Honest Cop, and the irreverent sense of humour \\\n",
        "it boasts is worth a few genuine laughs. But poor acting, \\\n",
        "and lack of any meaningful story or themes mean \\\n",
        "it is ultimately forgettable and messy.\"\n",
        "\n",
        "pred=get_prediction(text)\n",
        "print('class:', labels_dict[pred])\n",
        "\n",
        "text = \"Donald Trump saved the world\"\n",
        "\n",
        "pred=get_prediction(text)\n",
        "print('class:', labels_dict[pred])"
      ],
      "metadata": {
        "id": "RTgbZVxRBB6I",
        "outputId": "8dcaba8a-892f-427e-c40b-498d7816ad03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class: False\n",
            "class: False\n"
          ]
        }
      ]
    }
  ]
}